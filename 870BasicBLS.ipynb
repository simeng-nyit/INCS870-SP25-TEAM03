{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu01qmBCpagn",
        "outputId": "ee582d3a-db39-47e9-8343-097a51b9ed64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accurate is 99.913 %\n",
            "Training time is  8.502995014190674 s\n",
            "Testing accurate is 99.81700000000001 %\n",
            "Testing time is  1.1878211498260498 s\n",
            "test accuracy: [[0.99817]]\n",
            "training accuracy: [[0.99913]]\n",
            "test time spent: [[1.18782115]]\n",
            "training time spent: [[8.50299501]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv('UNSW_NB15_training-set.csv')\n",
        "test_data = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Define categorical columns\n",
        "categorical_cols = ['proto', 'service', 'state']\n",
        "\n",
        "# Initialize OneHotEncoder to ignore unknown categories\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "\n",
        "# Fit encoder on training data\n",
        "encoder.fit(train_data[categorical_cols])\n",
        "\n",
        "# Transform both train and test data\n",
        "train_encoded = encoder.transform(train_data[categorical_cols])\n",
        "test_encoded = encoder.transform(test_data[categorical_cols])\n",
        "\n",
        "# Convert encoded arrays to DataFrames\n",
        "train_encoded_df = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "test_encoded_df = pd.DataFrame(test_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "\n",
        "# Drop original categorical columns and merge encoded data\n",
        "train_data = pd.concat([train_data.drop(categorical_cols, axis=1), train_encoded_df], axis=1)\n",
        "test_data = pd.concat([test_data.drop(categorical_cols, axis=1), test_encoded_df], axis=1)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train = train_data.drop('label', axis=1)\n",
        "y_train = train_data['label']\n",
        "X_test = test_data.drop('label', axis=1)\n",
        "y_test = test_data['label']\n",
        "\n",
        "# Convert labels to one-hot format\n",
        "label_encoder = OneHotEncoder(sparse_output=False)\n",
        "y_train_onehot = label_encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_onehot = label_encoder.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Handle remaining categorical features in X (if any)\n",
        "categorical_cols_x = X_train.select_dtypes(include=['object']).columns\n",
        "if not categorical_cols_x.empty:\n",
        "    encoder_x = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "    X_train_encoded = encoder_x.fit_transform(X_train[categorical_cols_x])\n",
        "    X_test_encoded = encoder_x.transform(X_test[categorical_cols_x])\n",
        "    X_train = pd.concat([X_train.drop(categorical_cols_x, axis=1),\n",
        "                         pd.DataFrame(X_train_encoded, columns=encoder_x.get_feature_names_out(categorical_cols_x))], axis=1)\n",
        "    X_test = pd.concat([X_test.drop(categorical_cols_x, axis=1),\n",
        "                        pd.DataFrame(X_test_encoded, columns=encoder_x.get_feature_names_out(categorical_cols_x))], axis=1)\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "from BroadLearningSystem import BLS\n",
        "\n",
        "# BLS parameters\n",
        "s = 0.8    # Convergence coefficient\n",
        "c = 2**-30 # Regularization coefficient\n",
        "N1 = 10    # Feature nodes per window\n",
        "N2 = 10    # Number of windows\n",
        "N3 = 100   # Enhancement nodes\n",
        "\n",
        "# Running BLS\n",
        "test_acc, test_time, train_acc, train_time = BLS(\n",
        "    train_x=X_train_scaled,\n",
        "    train_y=y_train_onehot,  # Use one-hot encoded labels\n",
        "    test_x=X_test_scaled,\n",
        "    test_y=y_test_onehot,     # Use one-hot encoded labels\n",
        "    s=s,\n",
        "    c=c,\n",
        "    N1=N1,\n",
        "    N2=N2,\n",
        "    N3=N3\n",
        ")\n",
        "\n",
        "# print outcome\n",
        "print(\"test accuracy:\", test_acc)\n",
        "print(\"training accuracy:\", train_acc)\n",
        "print(\"test time spent:\", test_time)\n",
        "print(\"training time spent:\", train_time)"
      ]
    }
  ]
}