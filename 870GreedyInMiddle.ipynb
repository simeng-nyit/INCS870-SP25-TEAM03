{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CStATFa3zMkV",
        "outputId": "ccd5b150-bb08-4492-8514-46944a502c3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original dimensions:\n",
            "Training set: (175341, 45), Test set: (82332, 45)\n",
            "\n",
            "After dropping columns:\n",
            "Training set: (175341, 43), Test set: (82332, 43)\n",
            "\n",
            "Final preprocessed dimensions:\n",
            "X_train: (175341, 193), y_train: (175341, 2)\n",
            "X_test: (82332, 193), y_test: (82332, 2)\n",
            "\n",
            "BLS Input Dimensions:\n",
            "Training data: (175341, 193) → (175341, 2)\n",
            "Testing data: (82332, 193) → (82332, 2)\n",
            "============================================================\n",
            "Running Original BLS:\n",
            "Training accuracy is 92.865 %\n",
            "Training time is  11.46986436843872 s\n",
            "Testing accuracy is 80.416 %\n",
            "Testing time is  1.9780833721160889 s\n",
            "\n",
            "============================================================\n",
            "Running BLS with Greedy Bundling:\n",
            "\n",
            "Training feature matrix dimension after bundling: (175341, 12)\n",
            "Training accuracy is 91.499 %\n",
            "Training time is  46.36933469772339 s\n",
            "Testing accuracy is 78.113 %\n",
            "Testing time is  1.9864108562469482 s\n",
            "\n",
            "============================================================\n",
            "Metric                    | Original BLS    | Bundled BLS    \n",
            "------------------------------------------------------------\n",
            "Training Accuracy         | 0.9286          | 0.9150         \n",
            "Training Time (s)         | 11.4699         | 46.3693        \n",
            "Testing Accuracy          | 0.8042          | 0.7811         \n",
            "Testing Time (s)          | 1.9781          | 1.9864         \n"
          ]
        }
      ],
      "source": [
        "# Full code with greedy bundling\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import numpy as np\n",
        "from scipy import linalg as LA\n",
        "import time\n",
        "from BroadLearningSystemGreedyBundling2 import BLS\n",
        "\n",
        "# 数据预处理部分\n",
        "def load_and_preprocess():\n",
        "    # 读取数据\n",
        "    train_data = pd.read_csv('UNSW_NB15_training-set.csv')\n",
        "    # train_data = train_data.iloc[:, 1:]\n",
        "\n",
        "    test_data = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
        "    # test_data = test_data.iloc[:, 1:]\n",
        "\n",
        "    print(\"\\nOriginal dimensions:\")\n",
        "    print(f\"Training set: {train_data.shape}, Test set: {test_data.shape}\")\n",
        "\n",
        "    # Safely remove columns by position\n",
        "    def drop_columns(df):\n",
        "        # Column 0 = 'id', Column -2 = 'attack_cat' (before label)\n",
        "        return df.drop(df.columns[[0, -2]], axis=1)\n",
        "\n",
        "    train_data = drop_columns(train_data)\n",
        "    test_data = drop_columns(test_data)\n",
        "\n",
        "    print(\"\\nAfter dropping columns:\")\n",
        "    print(f\"Training set: {train_data.shape}, Test set: {test_data.shape}\")\n",
        "\n",
        "    # Rest of the original preprocessing code remains unchanged\n",
        "    train_data = train_data.iloc[:, 1:]  # Original first column removal (keep if needed)\n",
        "    test_data = test_data.iloc[:, 1:]\n",
        "\n",
        "\n",
        "    # 处理分类特征\n",
        "    categorical_cols = ['proto', 'service', 'state']\n",
        "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "\n",
        "    # 训练集编码\n",
        "    train_encoded = encoder.fit_transform(train_data[categorical_cols])\n",
        "    train_encoded_df = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "    train_data = pd.concat([train_data.drop(categorical_cols, axis=1), train_encoded_df], axis=1)\n",
        "\n",
        "    # 测试集编码\n",
        "    test_encoded = encoder.transform(test_data[categorical_cols])\n",
        "    test_encoded_df = pd.DataFrame(test_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "    test_data = pd.concat([test_data.drop(categorical_cols, axis=1), test_encoded_df], axis=1)\n",
        "\n",
        "    # 分割特征标签\n",
        "    X_train = train_data.drop('label', axis=1)\n",
        "    y_train = train_data['label']\n",
        "    X_test = test_data.drop('label', axis=1)\n",
        "    y_test = test_data['label']\n",
        "\n",
        "    # 标签编码\n",
        "    label_encoder = OneHotEncoder(sparse_output=False)\n",
        "    y_train_onehot = label_encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
        "    y_test_onehot = label_encoder.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "    # 处理剩余分类特征\n",
        "    categorical_cols_x = X_train.select_dtypes(include=['object']).columns\n",
        "    if not categorical_cols_x.empty:\n",
        "        encoder_x = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "        X_train_encoded = encoder_x.fit_transform(X_train[categorical_cols_x])\n",
        "        X_test_encoded = encoder_x.transform(X_test[categorical_cols_x])\n",
        "        X_train = pd.concat([X_train.drop(categorical_cols_x, axis=1),\n",
        "                            pd.DataFrame(X_train_encoded, columns=encoder_x.get_feature_names_out(categorical_cols_x))], axis=1)\n",
        "        X_test = pd.concat([X_test.drop(categorical_cols_x, axis=1),\n",
        "                           pd.DataFrame(X_test_encoded, columns=encoder_x.get_feature_names_out(categorical_cols_x))], axis=1)\n",
        "\n",
        "    # 标准化\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Final dimensions before returning\n",
        "    print(\"\\nFinal preprocessed dimensions:\")\n",
        "    print(f\"X_train: {X_train_scaled.shape}, y_train: {y_train_onehot.shape}\")\n",
        "    print(f\"X_test: {X_test_scaled.shape}, y_test: {y_test_onehot.shape}\")\n",
        "\n",
        "    return X_train_scaled, y_train_onehot, X_test_scaled, y_test_onehot\n",
        "\n",
        "\n",
        "def run_comparison():\n",
        "    X_train, y_train, X_test, y_test = load_and_preprocess()\n",
        "\n",
        "    # Print input dimensions for BLS\n",
        "    print(\"\\nBLS Input Dimensions:\")\n",
        "    print(f\"Training data: {X_train.shape} → {y_train.shape}\")\n",
        "    print(f\"Testing data: {X_test.shape} → {y_test.shape}\")\n",
        "\n",
        "    params = {\n",
        "        's': 0.5,      # Shrinkage coefficient\n",
        "        'c': 1e-5,     # Regularization coefficient\n",
        "        'N1': 10,      # Nodes per feature window\n",
        "        'N2': 10,      # Number of feature windows\n",
        "        'N3': 50       # Enhancement nodes\n",
        "    }\n",
        "\n",
        "    print(\"=\"*60 + \"\\nRunning Original BLS:\")\n",
        "    orig_results = BLS(X_train, y_train, X_test, y_test, K=None, **params)\n",
        "    # orig_results = BLS(X_train, y_train, X_test, y_test, **params)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60 + \"\\nRunning BLS with Greedy Bundling:\")\n",
        "    bundled_results = BLS(X_train, y_train, X_test, y_test, K=3, **params)\n",
        "    # bundled_results = BLS(X_train, y_train, X_test, y_test, **params)\n",
        "\n",
        "    # Print comparison table for greedy bundling in the middle\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"{'Metric':<25} | {'Original BLS':<15} | {'Bundled BLS':<15}\")\n",
        "    print(\"-\"*60)\n",
        "    print(f\"{'Training Accuracy':<25} | {orig_results[2]:<15.4f} | {bundled_results[2]:<15.4f}\")\n",
        "    print(f\"{'Training Time (s)':<25} | {orig_results[3]:<15.4f} | {bundled_results[3]:<15.4f}\")\n",
        "    print(f\"{'Testing Accuracy':<25} | {orig_results[0]:<15.4f} | {bundled_results[0]:<15.4f}\")\n",
        "    print(f\"{'Testing Time (s)':<25} | {orig_results[1]:<15.4f} | {bundled_results[1]:<15.4f}\")\n",
        "\n",
        "    # # Print comparison table for GOSS\n",
        "    # print(\"\\n\" + \"=\"*60)\n",
        "    # print(f\"{'Metric':<25} | {'Original BLS':<15} | {'Bundled BLS':<15}\")\n",
        "    # print(\"-\"*60)\n",
        "    # print(f\"{'Training Accuracy':<25} | {orig_results[0]:<15.4f} | {bundled_results[0]:<15.4f}\")\n",
        "    # print(f\"{'Training Time (s)':<25} | {orig_results[2]:<15.4f} | {bundled_results[2]:<15.4f}\")\n",
        "    # print(f\"{'Testing Accuracy':<25} | {orig_results[1]:<15.4f} | {bundled_results[1]:<15.4f}\")\n",
        "    # print(f\"{'Testing Time (s)':<25} | {orig_results[3]:<15.4f} | {bundled_results[3]:<15.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_comparison()"
      ]
    }
  ]
}